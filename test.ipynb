{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5b4db7-212d-4865-a76b-459a61aeda4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/venv_p5/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "save_path = f\"/home/jovyan/hdfs-jmt-rungjoo-private/save_models/facet/baseline_bart\"\n",
    "# model_path = \"/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/bart-base\"\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(save_path)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4994fddd-1fbc-4de1-9890-63841e51d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4b2994-5206-4079-8d82-092426455859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 3245,   293,  2726,    23,   462, 26970,   343]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = \"100 best weight watchers recipes\"\n",
    "query_string = \"1016\"\n",
    "query_string = \"caesars atlantic city\"\n",
    "inputs = tokenizer(query_string, padding=True, truncation=True, max_length=tokenizer.model_max_length, return_tensors='pt', add_special_tokens=False)\n",
    "inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e31bd8d3-e1de-494b-bf28-ca5c258e46f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caesars atlantic city'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a1c57b9-61fc-458a-ae10-f4a43f42806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = model.generate(inputs[\"input_ids\"])\n",
    "pred_facet_string = tokenizer.decode(token_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5099d81a-d948-4089-8143-98273211ed1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caesars parking atlantic city', 'caesars events atlatic city']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.strip() for x in pred_facet_string.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1ce45d1-f0c6-4c15-86e4-3a643f3a5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = {1:2}\n",
    "with open(\"result/baseline.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(test_result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b499d37-cbec-415d-92bd-ea9ef9fd981b",
   "metadata": {},
   "source": [
    "## 비교모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1db434-d888-427c-b421-b57832e28182",
   "metadata": {},
   "source": [
    "### gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45fa2f0e-da47-4acf-b363-06555251ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "gpt3_facets = {}\n",
    "with jsonlines.open(\"Faspect/gpt3_facets.jsonl\") as f:\n",
    "    for line in f.iter():\n",
    "        query = line['query']\n",
    "        pred = line['facets']\n",
    "        gpt3_facets[query] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51526560-b8dc-43a8-b94b-f58e8e5b2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"result/baseline.json\", 'r', encoding='utf-8') as f:\n",
    "    baseline = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1204463a-c85a-444b-9ae7-799f3a398ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3_facets_result = {}\n",
    "for ind, data in baseline.items():\n",
    "    query = data['query']\n",
    "    label = data['label']\n",
    "    pred = gpt3_facets[query]\n",
    "    \n",
    "    gpt3_facets_result[ind] = {}\n",
    "    gpt3_facets_result[ind]['query'] = query\n",
    "    gpt3_facets_result[ind]['pred'] = pred\n",
    "    gpt3_facets_result[ind]['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64b1d5f9-fb71-48c3-80db-cf05dd129dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result/gpt3_facets.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(gpt3_facets_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360983b-0b84-4932-a0a6-159fb1030cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ea85dd0-a4c8-4e4b-8282-0578fabf2bd6",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8b87f77-f21e-46d0-8a48-87431691a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact_p_list, exact_r_list, exact_f1_list = [], [], []\n",
    "# term_p_list, term_r_list, term_f1_list = [], [], []\n",
    "# for k, data in result.items():\n",
    "#     pred_list = data['pred']\n",
    "#     label_list = data['label']\n",
    "    \n",
    "#     exact_p, exact_r, exact_f1 = exact_match(pred_list, label_list)\n",
    "#     exact_p_list.append(exact_p)\n",
    "#     exact_r_list.append(exact_r)\n",
    "#     exact_f1_list.append(exact_f1)\n",
    "    \n",
    "#     term_p, term_r, term_f1 = term_overlap(pred_list, label_list)\n",
    "#     term_p_list.append(term_p)\n",
    "#     term_r_list.append(term_r)\n",
    "#     term_f1_list.append(term_f1)\n",
    "    \n",
    "# exact_p_score = sum(exact_p_list)/len(exact_p_list)\n",
    "# exact_r_score = sum(exact_r_list)/len(exact_r_list)\n",
    "# exact_f1_score = sum(exact_f1_list)/len(exact_f1_list)\n",
    "\n",
    "# term_p_score = sum(term_p_list)/len(term_p_list)\n",
    "# term_r_score = sum(term_r_list)/len(term_r_list)\n",
    "# term_f1_score = sum(term_f1_list)/len(term_f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82c7f58c-e3df-40ac-90cb-9dcf68b7171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23996873242106267, 0.23640788746720898, 0.23076348255784537)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exact_p_score, exact_r_score, exact_f1_score\n",
    "# term_p_score, term_r_score, term_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2109ef31-49f3-4054-ae9c-908abe40c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def exact_match_rung(pred_list, label_list):\n",
    "#     pred_list = [x.replace(\" \", \"\") for x in pred_list]\n",
    "#     label_list = [x.replace(\" \", \"\") for x in label_list]\n",
    "    \n",
    "#     pnum = 0\n",
    "#     for pred in pred_list:\n",
    "#         if pred in label_list:\n",
    "#             pnum += 1\n",
    "#     if len(pred_list) == 0:\n",
    "#         precision = 0                \n",
    "#     else:\n",
    "#         precision = pnum/len(pred_list)\n",
    "    \n",
    "#     rnum = 0\n",
    "#     for label in label_list:\n",
    "#         if label in pred_list:\n",
    "#             rnum += 1\n",
    "#     if len(label_list) == 0:\n",
    "#         recall = 0\n",
    "#     else:\n",
    "#         recall = rnum/len(label_list)\n",
    "        \n",
    "#     if precision == 0 or recall == 0:\n",
    "#         f1 = 0\n",
    "#     else:\n",
    "#         f1 = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "#     return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2df25a-be23-4060-8e4b-7a3be91a531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def term_overlap_rung(pred_list, label_list):\n",
    "#     pred_term = []\n",
    "#     for pred in pred_list:\n",
    "#         for term in pred.split(\" \"):\n",
    "#             if term not in pred_term:\n",
    "#                 pred_term.append(term)\n",
    "                \n",
    "#     label_term = []\n",
    "#     for label in label_list:\n",
    "#         for term in label.split(\" \"):\n",
    "#             if term not in label_term:\n",
    "#                 label_term.append(term)\n",
    "#     pnum = 0\n",
    "#     for pred in pred_term:\n",
    "#         if pred in label_term:\n",
    "#             pnum += 1\n",
    "#     if len(pred_term) == 0:\n",
    "#         precision = 0                \n",
    "#     else:\n",
    "#         precision = pnum/len(pred_term)\n",
    "    \n",
    "#     rnum = 0\n",
    "#     for label in label_term:\n",
    "#         if label in pred_term:\n",
    "#             rnum += 1\n",
    "#     if len(label_term) == 0:\n",
    "#         recall = 0\n",
    "#     else:\n",
    "#         recall = rnum/len(label_term)\n",
    "        \n",
    "#     if precision == 0 or recall == 0:\n",
    "#         f1 = 0\n",
    "#     else:\n",
    "#         f1 = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "#     return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad4c025-85c0-41ba-9dc5-ca2d292d0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"result/baseline.json\", 'r', encoding='utf-8') as f:\n",
    "    result = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a20384-d525-4982-92e9-becc03679421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from bert_score import score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "def best_bleu_cand(groundtruth, candidate):\n",
    "#     assert len(groundtruth) >= len(candidate)\n",
    "    all_permutations = list(itertools.permutations(candidate))\n",
    "    max_bleu = 0.\n",
    "    best_cand = all_permutations[0]\n",
    "    for cand in all_permutations:\n",
    "        bleu = 0.\n",
    "        for i in range(min(len(groundtruth), len(cand))):\n",
    "            bleu += sentence_bleu([groundtruth[i]], cand[i]) / len(groundtruth)\n",
    "        if bleu > max_bleu:\n",
    "            max_bleu = bleu\n",
    "            best_cand = cand\n",
    "    return list(best_cand)\n",
    "\n",
    "\n",
    "def eval_bleu(groundtruth, cand):\n",
    "    # Calculates the SET BLEU metrics, for 1-gram, 2-gram, 3-gram and 4-gram overlaps\n",
    "    best_cand = best_bleu_cand(groundtruth, cand)\n",
    "    bleu = [0., 0., 0., 0.]\n",
    "    bleu_weights = [[1, 0, 0, 0], [0.5, 0.5, 0, 0], [0.33, 0.33, 0.33, 0], [0.25, 0.25, 0.25, 0.25]]\n",
    "    for j in range(4):\n",
    "        for i in range(min(len(groundtruth), len(best_cand))):\n",
    "            bleu[j] += sentence_bleu([groundtruth[i]], best_cand[i], weights=bleu_weights[j]) / len(groundtruth)\n",
    "    return bleu\n",
    "\n",
    "\n",
    "def bertscore(groundtruth, cand):\n",
    "    # Calculates the Set BERT-Score metrics for Precision, Recall & F1\n",
    "    best_cand = best_bleu_cand(groundtruth, cand)\n",
    "    (P, R, F), hashname = score(best_cand, groundtruth, lang=\"en\", return_hash=True, device=\"cuda:0\")\n",
    "    return P.mean().item(), R.mean().item(), F.mean().item()\n",
    "\n",
    "\n",
    "def exact_match(groundtruth, cand):\n",
    "    # Calculates the exact match Precision, Recall & F1\n",
    "    c = 0.\n",
    "    for x in cand:\n",
    "        if x != '' and x in groundtruth:\n",
    "            c += 1\n",
    "    p = c / (len([x for x in cand if x != ''])+1e-8)\n",
    "    r = c / (len([x for x in groundtruth if x != ''])+1e-8)\n",
    "    f1 = 2 * p * r / (p + r) if p + r > 0 else 0.\n",
    "    return [p, r, f1]\n",
    "\n",
    "\n",
    "def term_match(groundtruth, cand):\n",
    "    # Calculates the term overlap Precision, Recall & F1\n",
    "    gt_terms = set([])\n",
    "    for x in groundtruth:\n",
    "        if x == '':\n",
    "            continue\n",
    "        for t in x.strip().split():\n",
    "            gt_terms.add(t)\n",
    "    cand_terms = set([])\n",
    "    for x in cand:\n",
    "        if x == '':\n",
    "            continue\n",
    "        for t in x.strip().split():\n",
    "            cand_terms.add(t)\n",
    "\n",
    "    c = 0.\n",
    "    for x in cand_terms:\n",
    "        if x != '' and x in gt_terms:\n",
    "            c += 1\n",
    "    p = c / (len([x for x in cand_terms if x != ''])+1e-8)\n",
    "    r = c / (len([x for x in gt_terms if x != ''])+1e-8)\n",
    "    f1 = 2 * p * r / (p + r) if p + r > 0 else 0.\n",
    "    return [p, r, f1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96354a76-b186-4368-aed1-f00947ffeb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0df07b1-d8c7-42ba-93e7-a0c3190f9c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are medicare services taxable in california', 'are medicare', 'social security', '']\n",
      "['design services', 'consulting services', 'insurance services', 'construction services']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "P_list, R_list, F_list = [], [], []\n",
    "for k, data in result.items():\n",
    "    pred_list = data['pred']\n",
    "    label_list = data['label']\n",
    "    \n",
    "    if len(label_list) > len(pred_list):\n",
    "        label_list = label_list[:len(pred_list)]\n",
    "    else:\n",
    "        pred_list = pred_list[:len(label_list)]   \n",
    "        \n",
    "    results = bertscore.compute(predictions=pred_list, references=label_list, lang=\"en\", device=\"cuda:0\")\n",
    "    precision, recall, f1 = results['precision'], results['recall'], results['f1']\n",
    "    P, R, F = sum(precision)/len(precision), sum(recall)/len(recall), sum(f1)/len(f1)    \n",
    "    P_list.append(precision)\n",
    "    R_list.append(recall)\n",
    "    F_list.append(f1)\n",
    "    \n",
    "    if (0 in precision) or (0 in recall) or (0 in f1):\n",
    "        print(pred_list)\n",
    "        print(label_list)\n",
    "        break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4abffbac-2b87-443c-ae09-ad607b3cf01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are medicare services taxable in california',\n",
       " 'are medicare',\n",
       " 'social security',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d74253bf-a935-4ea1-9590-276147e2fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = batch_pred[0]\n",
    "references = batch_label[0][:2]\n",
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\", device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10680b00-76f4-4661-ba60-d44b0e71691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\", device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc831caf-54c0-49d0-ae9e-7770d544bea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.958801805973053, 0.9332197904586792],\n",
       " [0.9588017463684082, 0.9316922426223755],\n",
       " [0.958801805973053, 0.9324553608894348])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1 = results['precision'], results['recall'], results['f1']\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81417cd0-954e-4075-8e1b-dd2f6f22cc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4ae45-55cb-4f0e-a996-b1de94828137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de2619-f3b2-418d-a7ec-13b3028ea1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = [\"for sale\", \"used cars\", \"electric\", \"cheap\"]\n",
    "cand = [\"afforable cars\", \"cars for sale\", \"used\", \"electric\"]\n",
    "cand = best_bleu_cand(groundtruth, cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432c7a9f-d9a0-40bf-baf4-65293369f3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term overlap metrics: P=0.8333333319444445,R=0.8333333319444445,F1=0.8333333319444444\n",
      "Exact match metrics: P=0.249999999375,R=0.249999999375,F1=0.249999999375\n"
     ]
    }
   ],
   "source": [
    "term_overlap_metrics = term_match(groundtruth, cand)\n",
    "print(\"Term overlap metrics: P={},R={},F1={}\".format(term_overlap_metrics[0],\n",
    "                                                     term_overlap_metrics[1],\n",
    "                                                     term_overlap_metrics[2]))\n",
    "\n",
    "exact_match_metrics = exact_match(groundtruth, cand)\n",
    "print(\"Exact match metrics: P={},R={},F1={}\".format(exact_match_metrics[0],\n",
    "                                                    exact_match_metrics[1],\n",
    "                                                    exact_match_metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b78e82-aa7b-42d6-aad5-8375e3b6b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/venv_p5/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jovyan/venv_p5/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jovyan/venv_p5/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.52904378163263,\n",
       " 0.47141237159386706,\n",
       " 0.4675886902868809,\n",
       " 0.46146832211337435]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_bleu(groundtruth, cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9146c3c3-6172-49de-b3eb-b3a44f4ac5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT score metrics: P=0.9065482020378113,R=0.9197155237197876,F1=0.9125113487243652\n"
     ]
    }
   ],
   "source": [
    "bert_score_metrics = bertscore(groundtruth, cand)\n",
    "print(\"BERT score metrics: P={},R={},F1={}\".format(bert_score_metrics[0],\n",
    "                                                   bert_score_metrics[1],\n",
    "                                                   bert_score_metrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15dc65-fd24-426b-bae6-e1ee2882f39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_p5",
   "language": "python",
   "name": "venv_p5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

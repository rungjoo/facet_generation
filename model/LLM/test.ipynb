{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19117b6a-2158-47f2-bd75-fcc557b1679a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data_path = f\"../../result/multitask_document_related.json\"\n",
    "with open(data_path, \"r\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba577d-6718-4e66-9445-fc946dcdced9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ce3756-f8a5-45ec-ba92-a2142a350530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workspace-main/venv_main/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 745/745 [00:00<00:00, 125kB/s]\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 15.9MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 2.36MB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|██████████| 51.0/51.0 [00:00<00:00, 52.9kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 384/384 [00:00<00:00, 415kB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# model_path = \"/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/upstage/llama-30b-instruct-2048\" # \"upstage/llama-30b-instruct-2048\" # 589 ms\n",
    "model_path = \"AIDC-ai-business/Luban-13B\" # \"JoSw-14/LoKuS-13B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) \n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_path,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf674c17-f12d-49df-8f48-bead23b32bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/AIDC-ai-business/Luban-13B/tokenizer_config.json',\n",
       " '/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/AIDC-ai-business/Luban-13B/special_tokens_map.json',\n",
       " '/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/AIDC-ai-business/Luban-13B/tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/AIDC-ai-business/Luban-13B\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27bca2de-52b7-4fb8-affe-752b16d55423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "CPU times: user 245 ms, sys: 3.13 ms, total: 249 ms\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_len = 0\n",
    "for ind, data in dataset.items():\n",
    "    label = \", \".join(data['label'])\n",
    "    inputs = tokenizer(label, return_tensors=\"pt\")\n",
    "    \n",
    "    input_len = inputs['input_ids'].shape[1]\n",
    "    if input_len > max_len:\n",
    "        max_len = input_len\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d43fe40-7a28-4809-8d9c-44da6a218f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "The predicted facets for 'caesars atlantic city' are 'parking, hotels'. But the correct facets are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\n",
      "The predicted facets for 'vista, ca' are 'parking, hotels'. But the correct facets are 'weather, zip code, population, homes for sale'\n",
      "\n",
      "As in the example above, modify the predicted facets.\n",
      "The predicted facets for 'device manager' are 'device manager, windows device manager'. What are the correct facets?\n",
      "\n",
      "### Assistant:\n",
      "The correct facets for 'device manager' are\n",
      " 'device manager, device manager windows 10, device manager windows 7\n",
      "['device manager', 'device manager windows 10', 'device manager windows 7']\n",
      "### Label:\n",
      "['open device manager', 'use device manager']\n",
      "0.6051514148712158\n"
     ]
    }
   ],
   "source": [
    "# upstage/llama-30b-instruct-2048\n",
    "# JoSw-14/LoKuS-13B\n",
    "import time\n",
    "for ind, data in dataset.items():\n",
    "    if int(ind) > 10:\n",
    "        st = time.time()\n",
    "        query = data['query']\n",
    "        pred_facet_list = data['pred']\n",
    "        pred_facets = \", \".join(pred_facet_list)\n",
    "\n",
    "        one_shot = \"\"\"### User:\\nThe predicted facets for 'caesars atlantic city' are 'parking, hotels'. But the correct facets are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\\n\"\"\"\n",
    "        two_shot = \"\"\"The predicted facets for 'vista, ca' are 'parking, hotels'. But the correct facets are 'weather, zip code, population, homes for sale'\\n\\n\"\"\"\n",
    "        # prompt = one_shot + two_shot + f\"\"\"As in the example above, modify the predicted facets.\\nThe predicted facets for '{query}' are '{pred_facets}'. What are the correct facets?\\n\\n### Assistant:\\n\"\"\"\n",
    "        prompt = one_shot + two_shot + f\"\"\"As in the example above, modify the predicted facets.\\nThe predicted facets for '{query}' are '{pred_facets}'. What are the correct facets?\\n\\n### Assistant:\\nThe correct facets for '{query}' are\"\"\"\n",
    "        print(prompt)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        label_str = \", \".join(data['label'])\n",
    "        label_inputs = tokenizer(label_str, return_tensors=\"pt\")\n",
    "        label_len = label_inputs['input_ids'].shape[1]\n",
    "\n",
    "        output = model.generate(**inputs, use_cache=True, max_new_tokens=int(label_len*2), temperature=0, top_p=1)\n",
    "        \n",
    "        output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        correct_facets = output[len(prompt):]\n",
    "        correct_facet_list = [x.strip() for x in correct_facets.strip().split(\"\\n\")[0].strip(\"'\").strip(\".\").strip(\"'\").split(\",\") if x.strip() != \"\"]\n",
    "        print(correct_facets)\n",
    "        print(correct_facet_list)\n",
    "        \n",
    "        print(\"### Label:\")\n",
    "        print(data['label'])\n",
    "        ed = time.time()\n",
    "        print(ed-st)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19220a96-4e48-4c3d-a05d-184aed7d59ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 'device manager, device manager windows 10, device manager windows 7\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ceb808-5996-4bb7-9a3d-99744c25e7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(dataset)*98/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d756450f-e4b2-47a1-b685-ba7f61cae0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "eng_rule = re.compile('\\'[a-zA-Z0-9,\\s]+\\'')\n",
    "correct_facets = \"\"\"\n",
    " 'download, installation, compatibility, updates'.\"\"\"\n",
    "correct_facets = \"\"\"\n",
    " 'suva beauty products, suva beauty salon, suva beauty reviews'\"\"\"\n",
    "print(correct_facets)\n",
    "correct_facet_list = [x.strip() for x in correct_facets.strip().strip(\"'\").strip(\".\").strip(\"'\").split(\",\") if x.strip() != \"\"]\n",
    "correct_facet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df7ef8e-577a-4214-a6c2-eeab78875047",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, data in dataset.items():\n",
    "    if int(ind) == 69:\n",
    "        query = data['query']\n",
    "        pred_facet_list = data['pred']\n",
    "        pred_facets = \", \".join(pred_facet_list)\n",
    "\n",
    "        one_shot = \"\"\"### User:\\nThe facets for 'caesars atlantic city' are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\\n\"\"\"\n",
    "        two_shot = \"\"\"The facets for 'vista, ca' are 'weather, zip code, population, homes for sale'\\n\\n\"\"\"\n",
    "        prompt = one_shot + two_shot + f\"\"\"### Assistant:\\nThe correct facets for '{query}' are\"\"\"\n",
    "        # prompt = one_shot + two_shot + f\"\"\"As in the examples above, create facets.\\nWhat facets correspond to the {query}?\\n\\n### Assistant:\\nThe correct facets for '{query}' are\"\"\"\n",
    "        print(prompt)\n",
    "        \n",
    "        label_str = \", \".join(data['label'])\n",
    "        label_inputs = tokenizer(label_str, return_tensors=\"pt\")\n",
    "        label_len = label_inputs['input_ids'].shape[1]\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        output = model.generate(**inputs, use_cache=True, max_new_tokens=int(label_len*1.5), temperature=0)\n",
    "        output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        correct_facets = output[len(prompt):]\n",
    "        print(correct_facets)\n",
    "        \n",
    "        print(\"### Label:\")\n",
    "        print(data['label'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d2215-e826-4bd1-be33-c31bfa50d7bd",
   "metadata": {},
   "source": [
    "## 에러 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7bc5b-a062-42d2-a90b-41c935e099bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "eng_rule = re.compile('\\'[a-zA-Z0-9\\-&.,\\s]+\\'')\n",
    "correct_facets = \"The correct facets for 'fps' are 'fps windows 10, fps windows 7, fps xbox one, fps ps4'.\"\n",
    "parsing = eng_rule.findall(correct_facets)\n",
    "print(parsing)\n",
    "correct_facet_list = [x.strip() for x in parsing[1].strip(\"'\").split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45d9a5-868a-4120-b5bb-f0d90feec80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_path = f\"../../result/LLM_multitask_document_related.json\"\n",
    "with open(data_path, \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "# data_path = f\"../../result/LLM_multitask_related_error.json\"\n",
    "# with open(data_path, \"r\") as f:\n",
    "#     dataset_error = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376ae9c-0553-4f06-9482-213362b597e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(dataset), len(dataset_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aebfef-2793-47c8-960b-af58013f1eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dataset = {}\n",
    "error_list = []\n",
    "for ind, data in dataset.items():\n",
    "    final_dataset[ind] = data\n",
    "    \n",
    "for ind, data in dataset_error.items():\n",
    "    query = data['query']\n",
    "    pred = data['pred']\n",
    "    filter_pred = pred.replace(f\"'{query}'\", '')\n",
    "    correct_facets = eng_rule.findall(filter_pred)\n",
    "    if len(correct_facets) == 1:\n",
    "        correct_facet_list = [x.strip() for x in correct_facets[0].strip(\"'\").split(\",\")]\n",
    "\n",
    "        final_dataset[ind] = {}\n",
    "        final_dataset[ind]['query'] = data['query']\n",
    "        final_dataset[ind]['pred'] = correct_facet_list\n",
    "        final_dataset[ind]['label'] = data['label']\n",
    "        final_dataset[ind]['options_overall_label'] = data['options_overall_label']\n",
    "    else:\n",
    "        # print(pred)\n",
    "        # print(filter_pred)\n",
    "        # print(correct_facets)\n",
    "        error_list.append([pred, correct_facets, data['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9abaf5-8432-481e-b97e-5a9af3d1bd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dataset = {}\n",
    "for ind, data in dataset.items():\n",
    "    final_dataset[ind] = {}\n",
    "    final_dataset[ind]['query'] = data['query']\n",
    "    final_dataset[ind]['pred'] = [x.strip(\"'\") for x in data['pred'] if x.strip()!=\"\"]\n",
    "    final_dataset[ind]['label'] = data['label']\n",
    "    final_dataset[ind]['options_overall_label'] = data['options_overall_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16796b-a1a9-4786-a2b2-16f52862f2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dataset['7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479f273-48d7-446b-a158-923869e6b28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path = f\"../../result/LLM_multitask_document_related.json\"\n",
    "with open(save_path, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(final_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caaff23-2b32-4ef4-b18d-8ff4d08f49d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"../../result/LLM_multitask_document_related1.json\"\n",
    "with open(save_path, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425056e-731f-48b6-b599-2b7294d3c3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_main",
   "language": "python",
   "name": "venv_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

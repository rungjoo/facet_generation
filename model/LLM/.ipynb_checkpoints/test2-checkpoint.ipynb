{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5b71c2-ccd4-4b54-a746-1151361c3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_path = f\"../../result/multitask_document_related.json\"\n",
    "with open(data_path, \"r\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b02cd4-e835-4e7b-bdf8-df7e2ac68276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# model_path = \"uukuguy/speechless-llama2-luban-orca-platypus-13b\" # \"garage-bAInd/GPlatty-30B\"\n",
    "model_path = \"/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/AIDC-ai-business/Luban-13B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b85661-f347-4bba-9843-8af2d8c8c3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/uukuguy/speechless-llama2-luban-orca-platypus-13b/tokenizer_config.json',\n",
       " '/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/uukuguy/speechless-llama2-luban-orca-platypus-13b/special_tokens_map.json',\n",
       " '/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/uukuguy/speechless-llama2-luban-orca-platypus-13b/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"/home/jovyan/hdfs-jmt-rungjoo-private/huggingface_models/uukuguy/speechless-llama2-luban-orca-platypus-13b\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ad73ef-585d-4985-a9c2-45b4b96692a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_prompt(query, pred_facets, method):\n",
    "    if method == \"post\":\n",
    "        one_shot = \"\"\"### User:\\nThe predicted facets for 'caesars atlantic city' are 'parking, hotels'. But the correct facets are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\\n\"\"\"\n",
    "        two_shot = \"\"\"The predicted facets for 'vista, ca' are 'parking, hotels'. But the correct facets are 'weather, zip code, population, homes for sale'\\n\\n\"\"\"\n",
    "        prompt = one_shot + two_shot + f\"\"\"As in the example above, modify the predicted facets.\\nThe predicted facets for '{query}' are '{pred_facets}'. What are the correct facets?\\n\\n### Assistant:\\nThe correct facets for '{query}' are\"\"\"    \n",
    "    else: # unseen\n",
    "        one_shot = \"\"\"### User:\\nThe facets for 'caesars atlantic city' are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\\n\"\"\"\n",
    "        two_shot = \"\"\"The facets for 'vista, ca' are 'weather, zip code, population, homes for sale'\\n\\n\"\"\"\n",
    "        prompt = one_shot + two_shot + f\"\"\"### Assistant:\\nThe correct facets for '{query}' are\"\"\"    \n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20b3d34-41c6-499d-b5be-73659a236953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "The predicted facets for 'caesars atlantic city' are 'parking, hotels'. But the correct facets are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\n",
      "The predicted facets for 'vista, ca' are 'parking, hotels'. But the correct facets are 'weather, zip code, population, homes for sale'\n",
      "\n",
      "As in the example above, modify the predicted facets.\n",
      "The predicted facets for 'new caledonia' are 'population, new caledonia zip code'. What are the correct facets?\n",
      "\n",
      "### Assistant:\n",
      "The correct facets for 'new caledonia' are\n",
      " 'geography, population, culture, economy, tourism, history'. The given facets 'population, new caledonia zip code' are too specific and not comprehensive enough to represent the diverse aspects of New Caledonia.##\n",
      "['geography', 'population', 'culture', 'economy', 'tourism', \"history'. The given facets 'population\", \"new caledonia zip code' are too specific and not comprehensive enough to represent the diverse aspects of New Caledonia.##\"]\n",
      "### Label:\n",
      "['new caledonia population', 'new caledonia flag', 'time in new caledonia', 'new caledonia news']\n",
      "1.8228459358215332\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/garage-bAInd/GPlatty-30B\n",
    "import time\n",
    "for ind, data in dataset.items():\n",
    "    if int(ind) > 8:\n",
    "        st = time.time()\n",
    "        query = data['query']\n",
    "        pred_facet_list = data['pred']\n",
    "        pred_facets = \", \".join(pred_facet_list)\n",
    "\n",
    "        method = \"post\"\n",
    "        prompt = make_prompt(query, pred_facets, method)\n",
    "        print(prompt)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        label_str = \", \".join(data['label'])\n",
    "        label_inputs = tokenizer(label_str, return_tensors=\"pt\")\n",
    "        label_len = label_inputs['input_ids'].shape[1]\n",
    "\n",
    "        output = model.generate(**inputs, use_cache=True, max_new_tokens=int(label_len*2), temperature=0, top_p=1)\n",
    "        \n",
    "        output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        correct_facets = output[len(prompt):]\n",
    "        correct_facet_list = [x.strip() for x in correct_facets.strip().split(\"\\n\")[0].strip(\"'\").strip(\".\").strip(\"'\").split(\",\") if x.strip() != \"\"]\n",
    "        print(correct_facets)\n",
    "        print(correct_facet_list)\n",
    "        \n",
    "        print(\"### Label:\")\n",
    "        print(data['label'])\n",
    "        ed = time.time()\n",
    "        print(ed-st)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c373a350-2607-437d-96da-13feb61e3d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'device manager, windows device manager'.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_facets.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed403f-c98d-4814-8923-c7476b996144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_main",
   "language": "python",
   "name": "venv_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

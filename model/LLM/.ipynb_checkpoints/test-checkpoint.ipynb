{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ce3756-f8a5-45ec-ba92-a2142a350530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workspace-main/venv_main/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "method = \"post\"\n",
    "model_name = \"upstage/llama-30b-instruct-2048\"\n",
    "model_str = model_name.replace(\"/\", \"_\")\n",
    "trained_model = \"multitask_document\"\n",
    "data_path = f\"../../result/{trained_model}.json\"\n",
    "\n",
    "# if method == \"post\": ## see small model  \n",
    "#     save_path = f\"../../result/LLM_{model_str}_{trained_model}.json\"\n",
    "#     error_path = f\"../../result/LLM_{model_str}_{trained_model}_error.json\"\n",
    "# else: ## zero (unseen)\n",
    "#     save_path = f\"../../result/LLM_{model_str}_{method}.json\"\n",
    "#     error_path = f\"../../result/LLM_{model_str}_{method}_error.json\"\n",
    "\n",
    "with open(data_path, \"r\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737141f3-d4df-42ea-873b-f65d826044bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2832"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1ecbcd-7608-438a-823a-07fba6ab6ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [01:19<00:00, 11.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 6656, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-59): 60 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=6656, out_features=6656, bias=False)\n",
       "          (k_proj): Linear(in_features=6656, out_features=6656, bias=False)\n",
       "          (v_proj): Linear(in_features=6656, out_features=6656, bias=False)\n",
       "          (o_proj): Linear(in_features=6656, out_features=6656, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=6656, out_features=17920, bias=False)\n",
       "          (up_proj): Linear(in_features=6656, out_features=17920, bias=False)\n",
       "          (down_proj): Linear(in_features=17920, out_features=6656, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=6656, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = f\"/home/jovyan/hdfs-jmt-rungjoo/huggingface_models/{model_name}\" # \"upstage/llama-30b-instruct-2048\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b041d62-608d-458e-b62f-814a7b88afe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_prompt(query, pred_facets, method):\n",
    "    if method == \"post\":\n",
    "        one_shot = \"\"\"### User:\\nThe predicted facets for 'caesars atlantic city' are 'parking, hotels'. But the correct facets are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\\n\"\"\"\n",
    "        two_shot = \"\"\"The predicted facets for 'vista, ca' are 'parking, hotels'. But the correct facets are 'weather, zip code, population, homes for sale'\\n\\n\"\"\"\n",
    "        prompt = one_shot + two_shot + f\"\"\"As in the example above, modify the predicted facets.\\nThe predicted facets for '{query}' are '{pred_facets}'. What are the correct facets?\\n\\n### Assistant:\\nThe correct facets for '{query}' are\"\"\"\n",
    "    elif method == \"zero\":\n",
    "        one_shot = \"\"\"### User:\\nThe facets for 'caesars atlantic city' are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\\n\"\"\"\n",
    "        two_shot = \"\"\"The facets for 'vista, ca' are 'weather, zip code, population, homes for sale'\\n\\n\"\"\"\n",
    "        prompt = one_shot + two_shot + f\"\"\"### Assistant:\\nThe correct facets for '{query}' are\"\"\"    \n",
    "    else: # noshot\n",
    "        prompt = \"### User:\\nThe facets for 'query' are 'facets'\\nAs in the format above, generate facets related to the query within 5, separated by ','.\\n\\n\"\n",
    "        prompt += f\"\"\"### Assistant:\\nThe facets for '{query}' are\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf674c17-f12d-49df-8f48-bead23b32bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2832 [00:00<?, ?it/s]/home/jovyan/workspace-main/venv_main/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/2832 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "method = 'noshot'\n",
    "\n",
    "eng_rule = re.compile('\\'.+\\'')    \n",
    "test_result = {}\n",
    "error_result = {}\n",
    "for k, data in tqdm(dataset.items()):\n",
    "    query = data['query']\n",
    "    pred_facet_list = data['pred']\n",
    "    pred_facets = \", \".join(pred_facet_list)\n",
    "    label = data['label']\n",
    "    options_overall_label = data['options_overall_label']\n",
    "\n",
    "    prompt = make_prompt(query, pred_facets, method)\n",
    "\n",
    "    label_inputs = tokenizer(pred_facets, return_tensors=\"pt\")\n",
    "    label_len = label_inputs['input_ids'].shape[1]        \n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    output = model.generate(**inputs, use_cache=True, max_new_tokens=int(label_len*2), temperature=0.001, top_p=1)\n",
    "    output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    correct_facets = output[len(prompt):]\n",
    "\n",
    "    try:\n",
    "        matches = eng_rule.findall(correct_facets.strip())\n",
    "        if len(matches) == 1:\n",
    "            correct_facet_list = [x.strip() for x in matches[0].strip(\"'\").split(\",\") if x.strip() != \"\"]\n",
    "        else:\n",
    "            correct_facet_list = [x.strip() for x in correct_facets.strip().split(\"\\n\")[0].strip(\"'\").strip(\".\").strip(\"'\").split(\",\") if x.strip() != \"\"]\n",
    "        test_result[k] = {}\n",
    "        test_result[k]['query'] = query\n",
    "        test_result[k]['pred'] = correct_facet_list\n",
    "        test_result[k]['label'] = label\n",
    "        test_result[k]['options_overall_label'] = options_overall_label\n",
    "    except:\n",
    "        error_result[k] = {}\n",
    "        error_result[k]['query'] = query\n",
    "        error_result[k]['pred'] = correct_facets\n",
    "        error_result[k]['label'] = label\n",
    "        error_result[k]['options_overall_label'] = options_overall_label     \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b78dfe-0457-45e8-9bab-316e3ee1c480",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "The facets for 'query' are 'facets'\n",
      "As in the format above, generate facets related to the query within 5, separated by ','.\n",
      "\n",
      "### Assistant:\n",
      "The facets for 'caesars atlantic city' are 'hotel, casino, entertainment, dining, location'.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e362a61a-eee0-4664-ad19-6e92bbd65c83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "The correct facets for 'caesars atlantic city' are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'.\n",
      "The correct facets for 'vista, ca' are 'weather, zip code, population, homes for sale'.\n",
      "\n",
      "As in the example above, predict the correct facets.\n",
      "\n",
      "### Assistant:\n",
      "The correct facets for 'caesars atlantic city' are\n"
     ]
    }
   ],
   "source": [
    "print(make_prompt(query, pred_facets, 'fewshot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d6d81-57d1-47ff-9dc6-ceb2b3a1a10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68fe06-00b9-4324-9238-36892aa3c408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212fb20-cb11-444b-b1bc-7281f732dccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7735e95-1444-428f-abb7-26799e5b7c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27bca2de-52b7-4fb8-affe-752b16d55423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "CPU times: user 245 ms, sys: 3.13 ms, total: 249 ms\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_len = 0\n",
    "for ind, data in dataset.items():\n",
    "    label = \", \".join(data['label'])\n",
    "    inputs = tokenizer(label, return_tensors=\"pt\")\n",
    "    \n",
    "    input_len = inputs['input_ids'].shape[1]\n",
    "    if input_len > max_len:\n",
    "        max_len = input_len\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d2215-e826-4bd1-be33-c31bfa50d7bd",
   "metadata": {},
   "source": [
    "## 에러 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7bc5b-a062-42d2-a90b-41c935e099bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "eng_rule = re.compile('\\'[a-zA-Z0-9\\-&.,\\s]+\\'')\n",
    "correct_facets = \"The correct facets for 'fps' are 'fps windows 10, fps windows 7, fps xbox one, fps ps4'.\"\n",
    "parsing = eng_rule.findall(correct_facets)\n",
    "print(parsing)\n",
    "correct_facet_list = [x.strip() for x in parsing[1].strip(\"'\").split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45d9a5-868a-4120-b5bb-f0d90feec80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_path = f\"../../result/LLM_multitask_document_related.json\"\n",
    "with open(data_path, \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "# data_path = f\"../../result/LLM_multitask_related_error.json\"\n",
    "# with open(data_path, \"r\") as f:\n",
    "#     dataset_error = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376ae9c-0553-4f06-9482-213362b597e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(dataset), len(dataset_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aebfef-2793-47c8-960b-af58013f1eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dataset = {}\n",
    "error_list = []\n",
    "for ind, data in dataset.items():\n",
    "    final_dataset[ind] = data\n",
    "    \n",
    "for ind, data in dataset_error.items():\n",
    "    query = data['query']\n",
    "    pred = data['pred']\n",
    "    filter_pred = pred.replace(f\"'{query}'\", '')\n",
    "    correct_facets = eng_rule.findall(filter_pred)\n",
    "    if len(correct_facets) == 1:\n",
    "        correct_facet_list = [x.strip() for x in correct_facets[0].strip(\"'\").split(\",\")]\n",
    "\n",
    "        final_dataset[ind] = {}\n",
    "        final_dataset[ind]['query'] = data['query']\n",
    "        final_dataset[ind]['pred'] = correct_facet_list\n",
    "        final_dataset[ind]['label'] = data['label']\n",
    "        final_dataset[ind]['options_overall_label'] = data['options_overall_label']\n",
    "    else:\n",
    "        # print(pred)\n",
    "        # print(filter_pred)\n",
    "        # print(correct_facets)\n",
    "        error_list.append([pred, correct_facets, data['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9abaf5-8432-481e-b97e-5a9af3d1bd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dataset = {}\n",
    "for ind, data in dataset.items():\n",
    "    final_dataset[ind] = {}\n",
    "    final_dataset[ind]['query'] = data['query']\n",
    "    final_dataset[ind]['pred'] = [x.strip(\"'\") for x in data['pred'] if x.strip()!=\"\"]\n",
    "    final_dataset[ind]['label'] = data['label']\n",
    "    final_dataset[ind]['options_overall_label'] = data['options_overall_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16796b-a1a9-4786-a2b2-16f52862f2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dataset['7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479f273-48d7-446b-a158-923869e6b28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path = f\"../../result/LLM_multitask_document_related.json\"\n",
    "with open(save_path, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(final_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caaff23-2b32-4ef4-b18d-8ff4d08f49d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"../../result/LLM_multitask_document_related1.json\"\n",
    "with open(save_path, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2425056e-731f-48b6-b599-2b7294d3c3c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xx=\"\"\"### User:\n",
    "The predicted facets for 'caesars atlantic city' are 'parking, hotels'. But the correct facets are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\n",
    "The predicted facets for 'vista, ca' are 'parking, hotels'. But the correct facets are 'weather, zip code, population, homes for sale'\n",
    "\n",
    "As in the example above, modify the predicted facets.\n",
    "The predicted facets for 'device manager' are 'device manager, windows device manager'. What are the correct facets?\n",
    "\n",
    "### Assistant:\n",
    "The correct facets for 'device manager' are\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a71cd9-dcf4-4039-b2bc-19276c631b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User:\n",
      "The predicted facets for 'caesars atlantic city' are 'parking, hotels'. But the correct facets are 'caesars atlantic city events, caesars atlantic city jobs, caesars atlantic city parking'\n",
      "The predicted facets for 'vista, ca' are 'parking, hotels'. But the correct facets are 'weather, zip code, population, homes for sale'\n",
      "\n",
      "As in the example above, modify the predicted facets.\n",
      "The predicted facets for 'device manager' are 'device manager, windows device manager'. What are the correct facets?\n",
      "\n",
      "### Assistant:\n",
      "The correct facets for 'device manager' are\n"
     ]
    }
   ],
   "source": [
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7739b2f-dd23-4f87-8e74-dd52212c6dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_main",
   "language": "python",
   "name": "venv_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

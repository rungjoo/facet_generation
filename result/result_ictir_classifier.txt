Term-overlapping
precision: 0.05944183800943824, recall: 0.04826397793976315, f1: 0.051064965064910275
Exact-matching
precision: 0.02767184549148229, recall: 0.029496233423136373, f1: 0.02760991158613156
Blue-score
bleu1: 0.09084295498226803, bleu2: 0.05059646326111129, bleu3: 0.036066068755114394, bleu4: 0.02910462190913459
BERTScore
precision: 0.4247977951741487, recall: 0.39976427880503385, f1: 0.4115941309368346

Filter Result - options_overall_label >= 1
Term-overlapping
precision: 0.057529829954293295, recall: 0.04804640852641772, f1: 0.05019964008754409
Exact-matching
precision: 0.028272217893730387, recall: 0.03055131133032743, f1: 0.028397722641714238
Blue-score
bleu1: 0.09251038742230216, bleu2: 0.05134972679796893, bleu3: 0.03671666715958349, bleu4: 0.02953509797121503
BERTScore
precision: 0.42528542128870844, recall: 0.4002137097574413, f1: 0.41205854634610883

#############Test Type: unique#############
Term-overlapping
precision: 0.06228499905128664, recall: 0.050197343794792786, f1: 0.05325406122043925
Exact-matching
precision: 0.028023538876971732, recall: 0.030079815915822292, f1: 0.0280570371260208
Blue-score
bleu1: 0.09362960038822532, bleu2: 0.05252443120529294, bleu3: 0.03769997550404936, bleu4: 0.030576929828926482
BERTScore
precision: 0.43619696236945266, recall: 0.4102164359291552, f1: 0.42249687446112

Filter Result - options_overall_label >= 1
Term-overlapping
precision: 0.05990469869372517, recall: 0.049774124936946974, f1: 0.052085032450364895
Exact-matching
precision: 0.028552515360444237, recall: 0.03114151210285133, f1: 0.028811344987907554
Blue-score
bleu1: 0.09562361615521064, bleu2: 0.05342266614665645, bleu3: 0.038339747374794, bleu4: 0.030997419391194464
BERTScore
precision: 0.43759956715886594, recall: 0.4115936237649025, f1: 0.4238827662994563


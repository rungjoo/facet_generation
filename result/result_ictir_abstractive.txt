Term-overlapping
precision: 0.287273608376442, recall: 0.30217911533544684, f1: 0.2840024365597282
Exact-matching
precision: 0.07459981137932369, recall: 0.06657250447230671, f1: 0.06836242241020422
Blue-score
bleu1: 0.42387039379088065, bleu2: 0.3466522956097138, bleu3: 0.3067125472658482, bleu4: 0.2821333348063966
BERTScore
precision: 0.8712263219760076, recall: 0.8839966270728872, f1: 0.8770191569270642

Filter Result - options_overall_label >= 1
Term-overlapping
precision: 0.2807557017871522, recall: 0.2959171159206174, f1: 0.2776484346948631
Exact-matching
precision: 0.0736885660440806, recall: 0.06564171099933488, f1: 0.0673884703030183
Blue-score
bleu1: 0.421979521701649, bleu2: 0.3438932787661755, bleu3: 0.30349098092339943, bleu4: 0.278708517364615
BERTScore
precision: 0.8704436721527339, recall: 0.8835663035853475, f1: 0.8764132419129143

#############Test Type: unique#############
Term-overlapping
precision: 0.3025842736502377, recall: 0.31900712515076085, f1: 0.2995829098064198
Exact-matching
precision: 0.08019480487319408, recall: 0.07202380926508854, f1: 0.07372899891091776
Blue-score
bleu1: 0.43801409940302444, bleu2: 0.3620464812212834, bleu3: 0.32260979943487844, bleu4: 0.29738918898248073
BERTScore
precision: 0.8738589095052545, recall: 0.885341284942543, f1: 0.8790270210735631

Filter Result - options_overall_label >= 1
Term-overlapping
precision: 0.295812247112276, recall: 0.312261439685632, f1: 0.29274531842564144
Exact-matching
precision: 0.07910414796324294, recall: 0.07095469230355879, f1: 0.07258997718627756
Blue-score
bleu1: 0.4359852088642563, bleu2: 0.3590369129960141, bleu3: 0.31916408243005157, bleu4: 0.29371673790980957
BERTScore
precision: 0.8730956554785476, recall: 0.8848838941542915, f1: 0.8784171284104352

